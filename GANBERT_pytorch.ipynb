{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANBERT_pytorch croce.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5f10011714c4be68f7596e59b2012a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e4f85674faa448788b268b561ae7143",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e869644e23704039b52ff5fc5137a06e",
              "IPY_MODEL_85bbf18d64c74a8db2d40f7eaa73ddc7"
            ]
          }
        },
        "5e4f85674faa448788b268b561ae7143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e869644e23704039b52ff5fc5137a06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5515e0169c934d2bb12c9b7ed5c2d3a8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_043006d4c0f84563ba9fb461de0720d1"
          }
        },
        "85bbf18d64c74a8db2d40f7eaa73ddc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71c080c39f2540d99efe5fff7ce3b16f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:07&lt;00:00, 54.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b036297cc25c47b7ad1945298e6dea6a"
          }
        },
        "5515e0169c934d2bb12c9b7ed5c2d3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "043006d4c0f84563ba9fb461de0720d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71c080c39f2540d99efe5fff7ce3b16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b036297cc25c47b7ad1945298e6dea6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2537da7b1f224141abde9dcf95e482a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6d7d8239eca4ba4b8291ac3ab63ce3f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c024d11974d4726b38b0ae5ba0177d6",
              "IPY_MODEL_dc6967cc8e2945d7979013f6e56fa2fe"
            ]
          }
        },
        "a6d7d8239eca4ba4b8291ac3ab63ce3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c024d11974d4726b38b0ae5ba0177d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d826d386fc76445582c34837fef87a85",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99bf857833ab4e88b679b7b7bb07f5f8"
          }
        },
        "dc6967cc8e2945d7979013f6e56fa2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a4fb590190849a8bec0a6c24f76f389",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:07&lt;00:00, 56.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df6b198e0034520b018aae1c94dbd37"
          }
        },
        "d826d386fc76445582c34837fef87a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99bf857833ab4e88b679b7b7bb07f5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a4fb590190849a8bec0a6c24f76f389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df6b198e0034520b018aae1c94dbd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c480efe2cb9432ba94bb2338094d5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bc4b2bfb73343e89a3f7bea2f0c3110",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de51dbf6a6654e6c928c54f9b67b25d4",
              "IPY_MODEL_8a68c5548ba8430f9333d58bc73022ea"
            ]
          }
        },
        "0bc4b2bfb73343e89a3f7bea2f0c3110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de51dbf6a6654e6c928c54f9b67b25d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36b1f1b53dd34cc795db316145a65887",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bda6090f86f4dfdb5f1c3102c0e78fa"
          }
        },
        "8a68c5548ba8430f9333d58bc73022ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_90afd1dbc6564203925390a95d226d40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 2.15MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f89f08ac2424a4dad1f2c93bb0b7556"
          }
        },
        "36b1f1b53dd34cc795db316145a65887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bda6090f86f4dfdb5f1c3102c0e78fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90afd1dbc6564203925390a95d226d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f89f08ac2424a4dad1f2c93bb0b7556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b4d85ae96134fecb7e7dc031f40cc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46be0602e7134ac2b3949ae519634fb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cab28f7254c4db6a8ea6d6c6cd04681",
              "IPY_MODEL_1e49255c33db4a6f887fbbacb048bde9"
            ]
          }
        },
        "46be0602e7134ac2b3949ae519634fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cab28f7254c4db6a8ea6d6c6cd04681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36ffcbe717a041ddba9784ce8895be21",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435797,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435797,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e513a86b3ad34fdc9870daf61652c6ac"
          }
        },
        "1e49255c33db4a6f887fbbacb048bde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b80fb825f5dc48db939658c09dde7142",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436k/436k [00:10&lt;00:00, 42.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cd2d4184e6c48e191d9b36031874741"
          }
        },
        "36ffcbe717a041ddba9784ce8895be21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e513a86b3ad34fdc9870daf61652c6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b80fb825f5dc48db939658c09dde7142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cd2d4184e6c48e191d9b36031874741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crux82/ganbert-pytorch/blob/main/GANBERT_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUpqAwtN8rTA"
      },
      "source": [
        "# GAN-BERT (in Pytorch and compatible with HuggingFace)\n",
        "\n",
        "This is an implementation in Pytorch (and **HuggingFace**) of the GAN-BERT method from https://github.com/crux82/ganbert which is available in Tensorflow.\n",
        "\n",
        "While the original GAN-BERT was an extension of BERT, this implementation can be adapted to several architectures, ranging from Roberta to Albert!\n",
        "\n",
        "**NOTE**: given that this implementation is different from the original one in Tensorflow, some results can be slighty different (but it alway improves the original BERT implementation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0m5KR34gmRH"
      },
      "source": [
        "Let's GO!\n",
        "\n",
        "Required Imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIqpm34x2rms",
        "outputId": "d098a09e-56f9-4377-e207-56a3781dbaa7"
      },
      "source": [
        "!pip install transformers==4.1.1\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import io\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "from transformers import *\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install sentencepiece\n",
        "\n",
        "##Set random values\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 20.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (4.41.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/36/59e4a62254c5fcb43894c6b0e9403ec6f4238cc2422a003ed2e6279a1784/tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 24.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=5c9803dbe88e0812cbef19eda748249a98bc48426ea039d192735140403b0068\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeZgRup520II",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00026c39-6c55-47a5-f3ec-500b0c8f7b91"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3ns8Ic7I-h"
      },
      "source": [
        "### Input Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw0HC_hU3FUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e808e792-6b92-4182-c0a7-8994e45cee69"
      },
      "source": [
        "max_seq_length = 64\n",
        "batch_size = 64\n",
        "learning_rate_discriminator = 2e-5\n",
        "learning_rate_generator = 2e-5\n",
        "noise_size = 100\n",
        "epsilon = 1e-8\n",
        "out_dropout_rate = 0.1\n",
        "apply_balance = True\n",
        "\n",
        "num_train_epochs = 10\n",
        "\n",
        "apply_scheduler = True\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "print_each_n_step = 10\n",
        "multi_gpu = True\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "#model_name = \"roberta-base\"\n",
        "#model_name = \"albert-base-v2\"\n",
        "#model_name = \"xlm-roberta-base\"\n",
        "#model_name = \"amazon/bort\"\n",
        "\n",
        "! git clone https://github.com/crux82/ganbert\n",
        "\n",
        "labeled_file = \"./ganbert/data/labeled.tsv\"\n",
        "unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
        "test_filename = \"./ganbert/data/test.tsv\"\n",
        "\n",
        "label_list = [\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \"NUM_weight\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ganbert'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 74 (delta 31), reused 49 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_ixn5qn_zV"
      },
      "source": [
        "Load the input QC dataset (fine-grained)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7cP8q7K3BId"
      },
      "source": [
        "def get_qc_examples(input_file):\n",
        "  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "  examples = []\n",
        "\n",
        "  with open(input_file, 'r') as f:\n",
        "      contents = f.read()\n",
        "      file_as_list = contents.splitlines()\n",
        "      for line in file_as_list[1:]:\n",
        "          split = line.split(\" \")\n",
        "          question = ' '.join(split[1:])\n",
        "\n",
        "          text_a = question\n",
        "          inn_split = split[0].split(\":\")\n",
        "          label = inn_split[0] + \"_\" + inn_split[1]\n",
        "          examples.append((text_a, label))\n",
        "      f.close()\n",
        "\n",
        "  return examples\n",
        "\n",
        "labeled_examples = get_qc_examples(labeled_file)\n",
        "unlabeled_examples = get_qc_examples(unlabeled_file)\n",
        "test_examples = get_qc_examples(test_filename)\n",
        "\n",
        "num_train_examples = len(labeled_examples) + len(unlabeled_examples)\n",
        "\n",
        "label_mask_rate = len(labeled_examples)/num_train_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Q5jzVioTHb"
      },
      "source": [
        "Load the Tranformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxghkkZq3Gbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "e5f10011714c4be68f7596e59b2012a1",
            "5e4f85674faa448788b268b561ae7143",
            "e869644e23704039b52ff5fc5137a06e",
            "85bbf18d64c74a8db2d40f7eaa73ddc7",
            "5515e0169c934d2bb12c9b7ed5c2d3a8",
            "043006d4c0f84563ba9fb461de0720d1",
            "71c080c39f2540d99efe5fff7ce3b16f",
            "b036297cc25c47b7ad1945298e6dea6a",
            "2537da7b1f224141abde9dcf95e482a3",
            "a6d7d8239eca4ba4b8291ac3ab63ce3f",
            "5c024d11974d4726b38b0ae5ba0177d6",
            "dc6967cc8e2945d7979013f6e56fa2fe",
            "d826d386fc76445582c34837fef87a85",
            "99bf857833ab4e88b679b7b7bb07f5f8",
            "5a4fb590190849a8bec0a6c24f76f389",
            "2df6b198e0034520b018aae1c94dbd37",
            "3c480efe2cb9432ba94bb2338094d5ef",
            "0bc4b2bfb73343e89a3f7bea2f0c3110",
            "de51dbf6a6654e6c928c54f9b67b25d4",
            "8a68c5548ba8430f9333d58bc73022ea",
            "36b1f1b53dd34cc795db316145a65887",
            "9bda6090f86f4dfdb5f1c3102c0e78fa",
            "90afd1dbc6564203925390a95d226d40",
            "2f89f08ac2424a4dad1f2c93bb0b7556",
            "1b4d85ae96134fecb7e7dc031f40cc23",
            "46be0602e7134ac2b3949ae519634fb8",
            "7cab28f7254c4db6a8ea6d6c6cd04681",
            "1e49255c33db4a6f887fbbacb048bde9",
            "36ffcbe717a041ddba9784ce8895be21",
            "e513a86b3ad34fdc9870daf61652c6ac",
            "b80fb825f5dc48db939658c09dde7142",
            "2cd2d4184e6c48e191d9b36031874741"
          ]
        },
        "outputId": "2e032c4b-93d7-4385-f75e-48bf0eb45c48"
      },
      "source": [
        "transformer = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "if torch.cuda.is_available():    \n",
        "  transformer.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5f10011714c4be68f7596e59b2012a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2537da7b1f224141abde9dcf95e482a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c480efe2cb9432ba94bb2338094d5ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4d85ae96134fecb7e7dc031f40cc23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBhaW5vBfR6B"
      },
      "source": [
        "Functions required to convert examples into Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmKL5AD7I4Zg"
      },
      "source": [
        "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
        "  '''\n",
        "  Generate a Dataloader given the input examples, eventually masked if they are \n",
        "  to be considered NOT labeled.\n",
        "  '''\n",
        "  examples = []\n",
        "\n",
        "  for index, ex in enumerate(input_examples): \n",
        "    if label_mask_rate == 1 or not balance_label_examples:\n",
        "      examples.append((ex, label_masks[index]))\n",
        "    else:\n",
        "      # IT SIMULATE A LABELED EXAMPLE\n",
        "      if label_masks[index]:\n",
        "        balance = int(1/label_mask_rate)\n",
        "        balance = int(math.log(balance,2))\n",
        "        if balance < 1:\n",
        "          balance = 1\n",
        "        for b in range(0, int(balance)):\n",
        "          examples.append((ex, label_masks[index]))\n",
        "      else:\n",
        "        examples.append((ex, label_masks[index]))\n",
        "\n",
        "  input_ids_array = []\n",
        "  input_mask_array = []\n",
        "  segment_ids_array = []\n",
        "  label_mask_array = []\n",
        "  label_id_array = []\n",
        "\n",
        "  for (text, label_mask) in examples: \n",
        "    input_ids = []\n",
        "    input_mask = []\n",
        "    tokens_a = tokenizer.tokenize(text[0])\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "      tokens.append(token)\n",
        "      segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    while len(input_ids) < max_seq_length:\n",
        "      input_ids.append(0)\n",
        "      input_mask.append(0)\n",
        "      segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    label_id = label_map[text[1]]\n",
        "\n",
        "    input_ids_array.append(torch.tensor(input_ids, dtype=torch.long)) \n",
        "    input_mask_array.append(torch.tensor(input_mask, dtype=torch.long))\n",
        "    segment_ids_array.append(torch.tensor(segment_ids, dtype=torch.long))\n",
        "    label_mask_array.append(label_mask)\n",
        "    label_id_array.append(label_id)\n",
        "\n",
        "  label_mask = np.array(label_mask_array)\n",
        "  label_id = np.array(label_id_array)\n",
        "\n",
        "  input_ids_array = torch.stack((input_ids_array),dim = 0)\n",
        "  input_mask_array = torch.stack((input_mask_array),dim = 0)\n",
        "  segment_ids_array = torch.stack((segment_ids_array),dim = 0)\n",
        "  label_masks = torch.tensor(label_mask)\n",
        "  label_ids = torch.tensor(label_id)\n",
        "\n",
        "  dataset = TensorDataset(input_ids_array, input_mask_array, label_ids, label_masks)\n",
        "\n",
        "  if do_shuffle:\n",
        "    sampler = RandomSampler\n",
        "  else:\n",
        "    sampler = SequentialSampler\n",
        "\n",
        "  return DataLoader(\n",
        "              dataset,  # The training samples.\n",
        "              sampler = sampler(dataset), \n",
        "              batch_size = batch_size) # Trains with this batch size.\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do3O-VeefT3g"
      },
      "source": [
        "Convert the input examples into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c-nsMXlKX-D"
      },
      "source": [
        "label_map = {}\n",
        "for (i, label) in enumerate(label_list):\n",
        "  label_map[label] = i\n",
        "#------------------------------\n",
        "#   Load the train dataset\n",
        "#------------------------------\n",
        "train_examples = labeled_examples\n",
        "#The labeled (train) dataset is assigned with a mask set to True\n",
        "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
        "#If unlabel examples are available\n",
        "if unlabeled_examples:\n",
        "  train_examples = train_examples + unlabeled_examples\n",
        "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
        "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
        "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
        "\n",
        "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
        "\n",
        "#------------------------------\n",
        "#   Load the test dataset\n",
        "#------------------------------\n",
        "#The labeled (test) dataset is assigned with a mask set to True\n",
        "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
        "\n",
        "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ihcw3vquaQm"
      },
      "source": [
        "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18kY64-n3I6y"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [noise_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output_rep = self.layers(noise)\n",
        "        return output_rep\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [input_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        self.layers = nn.Sequential(*layers) #per il flatten\n",
        "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input_rep, dropout_rate=0.1):\n",
        "        #input_rep = nn.Dropout(input_rep,dropout_rate=0.1) #dropout all'input?\n",
        "        last_rep = self.layers(input_rep)\n",
        "        logits = self.logit(last_rep)\n",
        "        probs = self.softmax(logits)\n",
        "        return last_rep, logits, probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uje9s2zQunFc"
      },
      "source": [
        "We instantiate the Discriminator and Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylz5rvqE3U2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fa2924-3fee-4bce-9a15-5a8bf9b2b1ba"
      },
      "source": [
        "# The config file is required to get the dimension of the vector produced by \n",
        "# the underlying transformer\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "hidden_size = int(config.hidden_size)\n",
        "print(config)\n",
        "\n",
        "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=[hidden_size], dropout_rate=out_dropout_rate)\n",
        "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=[hidden_size], num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "  generator.cuda()\n",
        "  discriminator.cuda()\n",
        "  if multi_gpu:\n",
        "    transformer = torch.nn.DataParallel(transformer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3qzp2-usZE"
      },
      "source": [
        "Let's go with the training procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhqylHGK3Va4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669e838e-654f-4640-b598-07a677f217a8"
      },
      "source": [
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "#models parameters\n",
        "transformer_vars = [i for i in transformer.parameters()]\n",
        "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
        "\n",
        "g_vars = [v for v in generator.parameters()]\n",
        "\n",
        "#optimizer\n",
        "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
        "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
        "\n",
        "#scheduler\n",
        "if apply_scheduler:\n",
        "  num_train_examples = len(train_examples)\n",
        "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
        "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "  scheduler_d = get_linear_schedule_with_warmup(dis_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps, \n",
        "                                           num_training_steps = num_train_steps)\n",
        "  scheduler_g = get_linear_schedule_with_warmup(gen_optimizer, \n",
        "                                           num_warmup_steps = num_warmup_steps, \n",
        "                                           num_training_steps = num_train_steps)\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, num_train_epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    tr_g_loss = 0\n",
        "    tr_d_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    transformer.train() \n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every print_each_n_step batches.\n",
        "        if step % print_each_n_step == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_label_mask = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        dis_optimizer.zero_grad()\n",
        "        gen_optimizer.zero_grad()\n",
        "\n",
        "        noise = torch.zeros(b_input_ids.shape[0],noise_size, device=device).uniform_(0, 1).requires_grad_(True)\n",
        "\n",
        "        #transformer\n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "        #discriminator\n",
        "        D_real_features, D_real_logits, D_real_probs = discriminator(hidden_states)\n",
        "\n",
        "        #generator\n",
        "        gen_rep = generator(noise)\n",
        "        #discriminator for generator\n",
        "        D_fake_features, D_fake_logits, D_fake_probs = discriminator(gen_rep.detach())\n",
        "        \n",
        "        #train discriminator\n",
        "        logits = D_real_logits[:,1:]\n",
        "        probabilities = F.softmax(logits, dim=-1)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
        "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
        "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
        "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
        "\n",
        "        if labeled_example_count==0:\n",
        "          D_L_Supervised=0\n",
        "        else:\n",
        "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
        "                 \n",
        "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
        "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
        "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
        "\n",
        "        #train generator\n",
        "        D_fake_features, D_fake_logits, D_fake_probs = discriminator(gen_rep) # for generator       \n",
        "        g_loss = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
        "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features.detach(), dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
        "        g_loss = g_loss + g_feat_reg\n",
        "\n",
        "        #generator backward\n",
        "        g_loss.backward()\n",
        "        gen_optimizer.step()\n",
        "\n",
        "        #discriminator backward\n",
        "        d_loss.backward()\n",
        "        dis_optimizer.step()\n",
        "\n",
        "        #accumulate loss\n",
        "        tr_g_loss += g_loss.item()\n",
        "        tr_d_loss += d_loss.item()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        if apply_scheduler:\n",
        "          scheduler_d.step()\n",
        "          scheduler_g.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
        "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss generetor: {0:.2f}\".format(avg_train_loss_g))\n",
        "    print(\"  Average training loss discriminator: {0:.2f}\".format(avg_train_loss_d))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #     TEST ON THE EVALUATION DATASET\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our test set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Test...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    transformer.eval() #maybe redundant\n",
        "    discriminator.eval()\n",
        "    generator.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_test_accuracy = 0\n",
        "   \n",
        "    total_test_loss = 0\n",
        "    nb_test_steps = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels_ids = []\n",
        "\n",
        "    #loss\n",
        "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_states = model_outputs[-1]\n",
        "            _, logits, probs = discriminator(hidden_states)\n",
        "            log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
        "            \n",
        "            # Accumulate the test loss.\n",
        "            total_test_loss += nll_loss(log_probs, b_labels)\n",
        "\n",
        "        # Accumulate the predictions and the input labels\n",
        "        logits = logits[:,1:]\n",
        "        _, preds = torch.max(logits, 1)\n",
        "        all_preds += preds.detach().cpu()\n",
        "        all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    all_preds = torch.stack(all_preds).numpy()\n",
        "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(test_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    test_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
        "    print(\"  Test took: {:}\".format(test_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss generator': avg_train_loss_g,\n",
        "            'Training Loss discriminator': avg_train_loss_d,\n",
        "            'Valid. Loss': avg_test_loss,\n",
        "            'Valid. Accur.': test_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Test Time': test_time\n",
        "        }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.11\n",
            "  Average training loss discriminator: 7.56\n",
            "  Training epcoh took: 0:01:04\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.11\n",
            "  Test Loss: 3.91\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:54.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss generetor: 0.10\n",
            "  Average training loss discriminator: 6.09\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.39\n",
            "  Test Loss: 3.85\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:28.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:35.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.07\n",
            "  Average training loss discriminator: 5.32\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.45\n",
            "  Test Loss: 3.82\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:28.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.07\n",
            "  Average training loss discriminator: 5.11\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.42\n",
            "  Test Loss: 3.76\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:28.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.07\n",
            "  Average training loss discriminator: 4.88\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.53\n",
            "  Test Loss: 3.72\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.07\n",
            "  Average training loss discriminator: 4.67\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.53\n",
            "  Test Loss: 3.75\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.07\n",
            "  Average training loss discriminator: 4.55\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.54\n",
            "  Test Loss: 3.73\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:28.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.08\n",
            "  Average training loss discriminator: 4.48\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.54\n",
            "  Test Loss: 3.71\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.08\n",
            "  Average training loss discriminator: 4.44\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.53\n",
            "  Test Loss: 3.71\n",
            "  Test took: 0:00:02\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     92.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     92.    Elapsed: 0:00:14.\n",
            "  Batch    30  of     92.    Elapsed: 0:00:21.\n",
            "  Batch    40  of     92.    Elapsed: 0:00:27.\n",
            "  Batch    50  of     92.    Elapsed: 0:00:34.\n",
            "  Batch    60  of     92.    Elapsed: 0:00:41.\n",
            "  Batch    70  of     92.    Elapsed: 0:00:48.\n",
            "  Batch    80  of     92.    Elapsed: 0:00:55.\n",
            "  Batch    90  of     92.    Elapsed: 0:01:02.\n",
            "\n",
            "  Average training loss generetor: 0.08\n",
            "  Average training loss discriminator: 4.39\n",
            "  Training epcoh took: 0:01:03\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.53\n",
            "  Test Loss: 3.71\n",
            "  Test took: 0:00:02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDm9NProRB4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61094e35-47e6-42cd-9724-3f1fd6f71043"
      },
      "source": [
        "for stat in training_stats:\n",
        "  print(stat)\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'epoch': 1, 'Training Loss generator': 0.11162844915752826, 'Training Loss discriminator': 7.564802874689517, 'Valid. Loss': tensor(3.9065, device='cuda:0'), 'Valid. Accur.': 0.11, 'Training Time': '0:01:04', 'Test Time': '0:00:02'}\n",
            "{'epoch': 2, 'Training Loss generator': 0.10451734479030837, 'Training Loss discriminator': 6.092482727506886, 'Valid. Loss': tensor(3.8542, device='cuda:0'), 'Valid. Accur.': 0.388, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 3, 'Training Loss generator': 0.07300473927803662, 'Training Loss discriminator': 5.315364254557568, 'Valid. Loss': tensor(3.8153, device='cuda:0'), 'Valid. Accur.': 0.448, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 4, 'Training Loss generator': 0.06840045377612114, 'Training Loss discriminator': 5.114511266998623, 'Valid. Loss': tensor(3.7553, device='cuda:0'), 'Valid. Accur.': 0.424, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 5, 'Training Loss generator': 0.06866135958420194, 'Training Loss discriminator': 4.876072126886119, 'Valid. Loss': tensor(3.7169, device='cuda:0'), 'Valid. Accur.': 0.526, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 6, 'Training Loss generator': 0.07184067530476529, 'Training Loss discriminator': 4.674337223820064, 'Valid. Loss': tensor(3.7495, device='cuda:0'), 'Valid. Accur.': 0.53, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 7, 'Training Loss generator': 0.07483236758929232, 'Training Loss discriminator': 4.5511068727659145, 'Valid. Loss': tensor(3.7258, device='cuda:0'), 'Valid. Accur.': 0.542, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 8, 'Training Loss generator': 0.0773193184286356, 'Training Loss discriminator': 4.4791176707848255, 'Valid. Loss': tensor(3.7052, device='cuda:0'), 'Valid. Accur.': 0.544, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 9, 'Training Loss generator': 0.07862798108354858, 'Training Loss discriminator': 4.437186712804048, 'Valid. Loss': tensor(3.7089, device='cuda:0'), 'Valid. Accur.': 0.53, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "{'epoch': 10, 'Training Loss generator': 0.07870624052441638, 'Training Loss discriminator': 4.391259486260622, 'Valid. Loss': tensor(3.7075, device='cuda:0'), 'Valid. Accur.': 0.526, 'Training Time': '0:01:03', 'Test Time': '0:00:02'}\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:10:51 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}